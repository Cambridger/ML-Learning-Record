{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prefix_stats(sorted_scores, sorted_defaults):\n",
    "\n",
    "    x = np.asarray(sorted_scores, dtype=float)\n",
    "    y = np.asarray(sorted_defaults, dtype=float)\n",
    "    n = len(x)\n",
    "    ps_x = np.concatenate(([0.0], np.cumsum(x)))\n",
    "    ps_x2 = np.concatenate(([0.0], np.cumsum(x * x)))\n",
    "    ps_y = np.concatenate(([0.0], np.cumsum(y)))\n",
    "    return ps_x, ps_x2, ps_y\n",
    "\n",
    "def interval_stats(ps_x, ps_x2, ps_y, i, j):\n",
    "\n",
    "    count = j - i + 1\n",
    "    sum_x = ps_x[j+1] - ps_x[i]\n",
    "    sum_x2 = ps_x2[j+1] - ps_x2[i]\n",
    "    sum_y = ps_y[j+1] - ps_y[i]\n",
    "    return count, sum_x, sum_x2, sum_y\n",
    "\n",
    "def optimal_buckets_mse(scores, defaults, K, min_bucket_size=1):\n",
    "\n",
    "    order = np.argsort(scores)\n",
    "    s = np.array(scores)[order]\n",
    "    d = np.array(defaults)[order]\n",
    "    n = len(s)\n",
    "    ps_x, ps_x2, ps_y = prefix_stats(s, d)\n",
    "\n",
    "\n",
    "    cost = np.full((n, n), np.inf)\n",
    "    for i in range(n):\n",
    "        for j in range(i + min_bucket_size -1, n):\n",
    "            cnt, sum_x, sum_x2, _ = interval_stats(ps_x, ps_x2, ps_y, i, j)\n",
    "            mean = sum_x / cnt\n",
    "            sse = sum_x2 - 2 * mean * sum_x + cnt * mean * mean\n",
    "            cost[i, j] = sse\n",
    "\n",
    "\n",
    "    K = int(K)\n",
    "    dp = np.full((K+1, n), np.inf)\n",
    "    prev = np.full((K+1, n), -1, dtype=int)\n",
    "\n",
    "    for j in range(min_bucket_size-1, n):\n",
    "        dp[1, j] = cost[0, j]\n",
    "        prev[1, j] = -1\n",
    "\n",
    "    for k in range(2, K+1):\n",
    "        for j in range(k*min_bucket_size -1, n):\n",
    "\n",
    "            i_min = (k-1)*min_bucket_size -1\n",
    "            best_val = np.inf\n",
    "            best_i = -1\n",
    "\n",
    "            for i in range(i_min, j - min_bucket_size + 1):\n",
    "                val = dp[k-1, i] + cost[i+1, j]\n",
    "                if val < best_val:\n",
    "                    best_val = val\n",
    "                    best_i = i\n",
    "            dp[k, j] = best_val\n",
    "            prev[k, j] = best_i\n",
    "\n",
    "\n",
    "    boundaries_idx = []\n",
    "    k = K\n",
    "    j = n-1\n",
    "    while k > 0:\n",
    "        i = prev[k, j]\n",
    "        start = 0 if i == -1 else i+1\n",
    "        boundaries_idx.append((start, j))\n",
    "        j = i\n",
    "        k -= 1\n",
    "    boundaries_idx = list(reversed(boundaries_idx))\n",
    "\n",
    "    buckets = []\n",
    "    for (i,j) in boundaries_idx:\n",
    "        cnt, sum_x, sum_x2, sum_y = interval_stats(ps_x, ps_x2, ps_y, i, j)\n",
    "        mean_score = sum_x / cnt\n",
    "        p_hat = sum_y / cnt\n",
    "        low, high = s[i], s[j]\n",
    "        sse = cost[i,j]\n",
    "        buckets.append({\n",
    "            'i': i, 'j': j, 'low': low, 'high': high,\n",
    "            'n': int(cnt), 'k': int(sum_y),\n",
    "            'p_hat': float(p_hat), 'mean_score': float(mean_score), 'sse': float(sse)\n",
    "        })\n",
    "    df = pd.DataFrame(buckets)\n",
    "    return df, order\n",
    "\n",
    "\n",
    "def interval_loglik(ps_x, ps_x2, ps_y, i, j, laplace_alpha=1.0):\n",
    "\n",
    "\n",
    "    cnt, sum_x, sum_x2, sum_y = interval_stats(ps_x, ps_x2, ps_y, i, j)\n",
    "    k = sum_y\n",
    "\n",
    "    p = (k + laplace_alpha) / (cnt + 2*laplace_alpha)\n",
    "    return k * np.log(p) + (cnt - k) * np.log(1 - p)\n",
    "\n",
    "def optimal_buckets_loglik(scores, defaults, K, min_bucket_size=1, laplace_alpha=1.0):\n",
    "\n",
    "    order = np.argsort(scores)\n",
    "    s = np.array(scores)[order]\n",
    "    d = np.array(defaults)[order]\n",
    "    n = len(s)\n",
    "    ps_x, ps_x2, ps_y = prefix_stats(s, d)\n",
    "\n",
    "\n",
    "    loglik = np.full((n, n), -np.inf)\n",
    "    for i in range(n):\n",
    "        for j in range(i + min_bucket_size -1, n):\n",
    "            loglik[i, j] = interval_loglik(ps_x, ps_x2, ps_y, i, j, laplace_alpha=laplace_alpha)\n",
    "\n",
    "\n",
    "    dp = np.full((K+1, n), -np.inf)\n",
    "    prev = np.full((K+1, n), -1, dtype=int)\n",
    "\n",
    "    for j in range(min_bucket_size-1, n):\n",
    "        dp[1, j] = loglik[0, j]\n",
    "        prev[1, j] = -1\n",
    "\n",
    "    for k in range(2, K+1):\n",
    "        for j in range(k*min_bucket_size -1, n):\n",
    "            best_val = -np.inf\n",
    "            best_i = -1\n",
    "            i_min = (k-1)*min_bucket_size -1\n",
    "            for i in range(i_min, j - min_bucket_size + 1):\n",
    "                val = dp[k-1, i] + loglik[i+1, j]\n",
    "                if val > best_val:\n",
    "                    best_val = val\n",
    "                    best_i = i\n",
    "            dp[k, j] = best_val\n",
    "            prev[k, j] = best_i\n",
    "\n",
    "\n",
    "    boundaries_idx = []\n",
    "    k = K\n",
    "    j = n-1\n",
    "    while k > 0:\n",
    "        i = prev[k, j]\n",
    "        start = 0 if i == -1 else i+1\n",
    "        boundaries_idx.append((start, j))\n",
    "        j = i\n",
    "        k -= 1\n",
    "    boundaries_idx = list(reversed(boundaries_idx))\n",
    "\n",
    "    buckets = []\n",
    "    for (i,j) in boundaries_idx:\n",
    "        cnt, sum_x, sum_x2, sum_y = interval_stats(ps_x, ps_x2, ps_y, i, j)\n",
    "        p_hat = (sum_y + laplace_alpha) / (cnt + 2*laplace_alpha)\n",
    "        low, high = s[i], s[j]\n",
    "        buckets.append({\n",
    "            'i': i, 'j': j, 'low': low, 'high': high,\n",
    "            'n': int(cnt), 'k': int(sum_y),\n",
    "            'p_hat': float(p_hat), 'mean_score': float(sum_x/cnt),\n",
    "            'loglik': float(interval_loglik(ps_x, ps_x2, ps_y, i, j, laplace_alpha=laplace_alpha))\n",
    "        })\n",
    "    df = pd.DataFrame(buckets)\n",
    "    return df, order\n",
    "\n",
    "\n",
    "def build_rating_map(df_buckets):\n",
    "\n",
    "\n",
    "    df = df_buckets.copy()\n",
    "\n",
    "    df = df.sort_values('mean_score', ascending=False).reset_index(drop=True)\n",
    "    df['rating'] = np.arange(1, len(df)+1)\n",
    "\n",
    "    mapping = df[['rating', 'low', 'high', 'p_hat', 'n', 'k', 'mean_score']]\n",
    "    return mapping\n",
    "\n",
    "def score_to_rating(score, mapping_df):\n",
    "\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        low = row['low']\n",
    "        high = row['high']\n",
    "\n",
    "        if low <= score <= high:\n",
    "            return int(row['rating'])\n",
    "\n",
    "    if score < mapping_df['low'].min():\n",
    "        return int(mapping_df['rating'].max())\n",
    "    else:\n",
    "        return int(mapping_df['rating'].min())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "    n = 2000\n",
    "    fic = rng.integers(300, 851, size=n)\n",
    "    prob = 1 / (1 + np.exp((fic - 600)/25)) * 0.5\n",
    "\n",
    "    labels = rng.binomial(1, prob)\n",
    "    K = 5\n",
    "\n",
    "    df_mse, order = optimal_buckets_mse(fic, labels, K, min_bucket_size=20)\n",
    "    print(\"MSE buckets (ascending FICO):\")\n",
    "    print(df_mse)\n",
    "\n",
    "    df_ll, order_ll = optimal_buckets_loglik(fic, labels, K, min_bucket_size=20, laplace_alpha=1.0)\n",
    "    print(\"\\nLog-likelihood buckets (ascending FICO):\")\n",
    "    print(df_ll)\n",
    "\n",
    "    rating_map_mse = build_rating_map(df_mse)\n",
    "    print(\"\\nRating map (MSE -> rating 1 best):\")\n",
    "    print(rating_map_mse)\n",
    "\n",
    "\n",
    "    test_score = 720\n",
    "    rating_for_test = score_to_rating(test_score, rating_map_mse)\n",
    "    print(f\"\\nSample score {test_score} -> rating {rating_for_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
